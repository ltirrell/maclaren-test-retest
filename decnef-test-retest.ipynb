{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Datasets\n",
    "\n",
    "```\n",
    "submit_subjects \\\n",
    "  --upload_metadata \\\n",
    "  --save_details \\\n",
    "  --stagger \\\n",
    "  -q reTHINQ-c5-spot \\\n",
    "  -t 1.0.0-rc.11 \\\n",
    "  -I s3://cmet-testsets/DecNefTS/ \\\n",
    "  -o s3://cmet-scratch/20200615-DecNefTS-1.0.0-rc.11/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy data locally\n",
    "\n",
    "```\n",
    "mkdir -p /home/paul/cmet/data/20200615-DecNefTS-1.0.0-rc.11\n",
    "cd /home/paul/cmet/data/20200615-DecNefTS-1.0.0-rc.11\n",
    "aws s3 cp s3://cmet-testsets/DecNefTS/demographics.tsv .\n",
    "aws s3 cp \\\n",
    "  --recursive \\\n",
    "  --exclude \"*\" \\\n",
    "  --include \"*subject_info.json\" \\\n",
    "  --include \"*.pdf\" \\\n",
    "  --include \"*.log\" \\\n",
    "  s3://cmet-scratch/20200615-DecNefTS-1.0.0-rc.11/DecNefTS/ .\n",
    "rm -f ./sub-058/cache/59d231cda1504d2d/rethinq/subject_info.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# imports find_json_files(); load_json_file(); load_dataset();\n",
    "from cmeds import *\n",
    "# imports calc_cvs(); session_permute(); monte_carlo_perm_test\n",
    "#from test_retest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_retest.py\n",
    "def calc_cvs(df, subject_list, session_list, subject_col, session_col, structs_of_interest, method='gluer'):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "        - a dataframe; as returned by load_dataset() (`df`)\n",
    "        - a list of subjects to iterate over (`subject_list`)\n",
    "        - a list of sessions to iterate over (`session_list`) \n",
    "          - maclaren method assummes all subjects have all sessions and each session has 2 repeated meas\n",
    "          - gluer method might assume 'all subjects have all sessions' (?)\n",
    "            - this is ok for decnef\n",
    "          - gluer doesn't assume all sessions have same num repeated measures\n",
    "        - the column name in the dataset's tsv that denotes subject_id (`subject_col`)\n",
    "        - the column name in the dataset's tsv that denotes session_id (`session_col`)\n",
    "        - a list of columns names in the dataframe over which to compute CoVs (`structs_of_interest`)\n",
    "        - method to employ to compute intra-session CoV ('maclaren' or 'gluer'; default='gluer')\n",
    "    Produce:\n",
    "        - a dataframe with the total coefficient of variation (CoV) for each element in `structs_of_interest` \n",
    "          (`total_cvs_df`)\n",
    "        - a datafram with the intra-session coefficient of variation (CoV) for each element in `structs_of_interest`\n",
    "          session_cvs_df  \n",
    "    See: \n",
    "        - [1] Maclaren, Julian, et al. \"Reliability of brain volume measurements: a test-retest dataset.\" \n",
    "          Scientific data 1.1 (2014): 1-9.\n",
    "        - [2]: Gl√ºer, C-C., et al. \"Accurate assessment of precision errors: how to measure the \n",
    "          reproducibility of bone densitometry techniques.\" Osteoporosis international 5.4 (1995): 262-270.\n",
    "    \"\"\"\n",
    "\n",
    "    # Holds the intra-session CoV for each subject/struct\n",
    "    # Will eventually be a numpy array\n",
    "    subject_session_cvs = None\n",
    "    # Holds the total CoV for each subject/struct\n",
    "    # Will eventually be a numpy array\n",
    "    subject_total_cvs = None\n",
    "    \n",
    "    for subject in subject_list:\n",
    "        # Select by subject; make a numpy array\n",
    "        subject_df = df[df[subject_col]==subject]\n",
    "        subject_level_vals = subject_df.loc[:,structs_of_interest].to_numpy()\n",
    "        \n",
    "        # same m used to compute sigma_s in [1]\n",
    "        m = 0\n",
    "\n",
    "        # Calculate total CoV for this subject\n",
    "        total_cvs = 100 * np.std(subject_level_vals,axis=0)/np.mean(subject_level_vals,axis=0)\n",
    "        if subject_total_cvs is None:\n",
    "            subject_total_cvs = total_cvs\n",
    "        else:           \n",
    "            subject_total_cvs = np.vstack((subject_total_cvs,total_cvs))\n",
    "\n",
    "        # Compute `subject_session_cvs` according to [1] or eq's 5 and 6 in [2]\n",
    "        if (method == 'maclaren'):\n",
    "            # Compute `session_cvs` a la Maclaren\n",
    "            \n",
    "            # To track the summation in $\\sigma_s = \\sqrt{\\frac{\\sum{(x_i'-x_i'')^2}}{2m}}$ in [1]\n",
    "            # Will eventually be a numpy array\n",
    "            subject_sum = None\n",
    "        \n",
    "            for session in session_list:\n",
    "                # Select by subject ADN session; make a numpy array\n",
    "                session_df = subject_df[subject_df[session_col]==session]\n",
    "                session_level_vals = session_df.loc[:,structs_of_interest].to_numpy()\n",
    "                \n",
    "                # At least one of the pairs did not get processed properly; skip\n",
    "                # this is fragile and probably needs more work\n",
    "                vals_has_a_nan = np.isnan(np.sum(session_level_vals))\n",
    "                if vals_has_a_nan:\n",
    "                    continue\n",
    "                # Number of sessions\n",
    "                m += 1\n",
    "                # np.diff() assumes only 2 measurments per session (as does MacLaren) and will break\n",
    "                # if anything else is passed\n",
    "                diff_squared = np.square(np.diff(session_level_vals,axis=0).flatten())\n",
    "                if subject_sum is None:\n",
    "                    subject_sum = diff_squared\n",
    "                else:\n",
    "                    subject_sum += diff_squared\n",
    "            # eq 1 in [1]        \n",
    "            sigma_s = np.sqrt(np.divide(subject_sum,2*m))\n",
    "            # eq 2 in [1]\n",
    "            session_cvs = 100 * sigma_s / np.mean(subject_level_vals,axis=0)\n",
    "                \n",
    "        elif (method=='gluer'):\n",
    "            # Compute `session_cvs` a la Gluer\n",
    "            \n",
    "            m = len(session_list)\n",
    "            # record the number of repeated measurements in each session and compute df\n",
    "            n_meas = []\n",
    "            for session in session_list:\n",
    "                n_meas.append(subject_df[subject_df[session_col]==session].shape[0])\n",
    "            # eq 7 in [2]\n",
    "            deg_freedom = np.sum(np.subtract(n_meas,1))\n",
    "\n",
    "            # counter for doube summation term of eq 6 in [2]\n",
    "            std_ctr_div_df = None\n",
    "            # counter for the summation term of eq 5 in [2]\n",
    "            x_j_over_m = None\n",
    "\n",
    "            for session in session_list:\n",
    "                session_df = subject_df[subject_df[session_col]==session]\n",
    "                session_level_vals = session_df.loc[:,structs_of_interest].to_numpy()\n",
    "                # summation in eq 6 in [2]\n",
    "                if std_ctr_div_df is None:\n",
    "                    std_ctr_div_df = np.sum(np.square(np.mean(session_level_vals,axis=0) - session_level_vals)/deg_freedom,axis=0)\n",
    "                else:\n",
    "                    std_ctr_div_df += np.sum(np.square(np.mean(session_level_vals,axis=0) - session_level_vals)/deg_freedom,axis=0)\n",
    "                # summation in eq 5 in [2]\n",
    "                if x_j_over_m is None:\n",
    "                    x_j_over_m = np.mean(session_level_vals,axis=0)/m\n",
    "                else:\n",
    "                    x_j_over_m += np.mean(session_level_vals,axis=0)/m                    \n",
    "            # eq 6 in [2]\n",
    "            sigma_s = np.sqrt(std_ctr_div_df)\n",
    "            # eq 5 in [2]\n",
    "            session_cvs = 100 * (sigma_s / x_j_over_m)            \n",
    "        else:\n",
    "            print('Balls')\n",
    "\n",
    "        # Record this subect's intra-session CoVs   \n",
    "        if subject_session_cvs is None:\n",
    "            subject_session_cvs = session_cvs\n",
    "        else:\n",
    "            subject_session_cvs = np.vstack((subject_session_cvs,session_cvs))            \n",
    "\n",
    "    # We now have:\n",
    "    # - `subject_session_cvs`: a n x k array of each subject's intra-session coefficient of variation for each \n",
    "    #    entry in `structs_of_interest`\n",
    "    # - `subject_total_cvs`: a n x k array of each subject's total coefficient of variation for each \n",
    "    #    entry in `structs_of_interest`\n",
    "    \n",
    "    # Take the mean of the coefficients of variation across subject for each struct,\n",
    "    # making sure to RMS average them together (not arithmetic avg)\n",
    "    # eq 4a in [2]\n",
    "    session_cvs = np.sqrt(np.mean(np.square(subject_session_cvs),axis=0))\n",
    "    total_cvs = np.sqrt(np.mean(np.square(subject_total_cvs),axis=0))\n",
    "\n",
    "    # Stuff results back into a dataframe    \n",
    "    total_cvs_series = pd.Series(total_cvs, index=structs_of_interest)\n",
    "    session_cvs_series = pd.Series(session_cvs, index=structs_of_interest)\n",
    "    abs_diff_cvs_series = pd.Series(np.abs(total_cvs - session_cvs), index=structs_of_interest)\n",
    "    # Ok dataframes are fun now..\n",
    "    means = df[ (df[subject_col].isin(subject_list)) & \\\n",
    "                (df[session_col].isin(session_list)) ] \\\n",
    "                  [structs_of_interest].mean()\n",
    "    idx = ['mean-vol','total-cov','session-cov','abs-diff-cov']\n",
    "    list_of_series = [means, total_cvs_series, session_cvs_series, abs_diff_cvs_series]\n",
    "    results = pd.DataFrame(list_of_series, columns=structs_of_interest, index=idx)\n",
    "    return results\n",
    "\n",
    "def session_permute(df, subject_list, subject_col, session_col):\n",
    "    '''\n",
    "    Given:\n",
    "        - a datafram (`df`)\n",
    "        - the list of subjects to operate over (`subject_list`)\n",
    "        - the column name in the dataset's tsv that denotes subject_id (`subject_col`)\n",
    "        - the column name in the dataset's tsv that denotes session_id (`session_col`)\n",
    "    Produce:\n",
    "        - a datafram where the session labels for every subject in `subject_list` has been randomly permuted\n",
    "    '''\n",
    "    \n",
    "    new_df = None\n",
    "    for subject in subject_list:\n",
    "        subject_df = df[df[subject_col]==subject]\n",
    "        session_list_random_permute = np.random.permutation(subject_df[session_col].to_numpy())\n",
    "        sub_idx = subject_df.index\n",
    "        subject_df_perm = subject_df.drop(session_col,axis=1)\n",
    "        subject_df_perm.insert(1,session_col,session_list_random_permute)\n",
    "        if new_df is None:\n",
    "            new_df = subject_df_perm\n",
    "        else:\n",
    "            new_df = new_df.append(subject_df_perm)        \n",
    "    return new_df\n",
    "\n",
    "def monte_carlo_perm_test(df, subject_list, session_list, subject_col, session_col, structs_of_interest, n_itrs=100, method='gluer'):\n",
    "\n",
    "    # Calculate the actual coefficients of variation for the dataset\n",
    "    cvs_df = calc_cvs(df,subject_list,session_list,subject_col,session_col,structs_of_interest,method=method)\n",
    "\n",
    "    # Now simulate how likely we are to observe an equal or greater difference \n",
    "    # by randomly permuting session_id's\n",
    "    counter = np.zeros(cvs_df.loc['abs-diff-cov'].to_numpy().shape)\n",
    "    for i in range(n_itrs):\n",
    "        permuted_df = session_permute(df, subject_list, subject_col, session_col)\n",
    "        simulated_cvs_df = calc_cvs(permuted_df,subject_list,session_list,subject_col,session_col,structs_of_interest,method=method)    \n",
    "        counter += 1 * (simulated_cvs_df.loc['abs-diff-cov'] >= cvs_df.loc['abs-diff-cov'])\n",
    "\n",
    "    pvals = (counter/n_itrs).rename('p-vals')\n",
    "    cvs_with_pval = cvs_df.append(pvals)\n",
    "\n",
    "    return cvs_with_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Vars\n",
    "decnef_dir = '/home/paul/cmet/data/20200615-DecNefTS-1.0.0-rc.11/'\n",
    "decnef_tsv = '/home/paul/cmet/data/20200615-DecNefTS-1.0.0-rc.11/demographics.tsv'\n",
    "\n",
    "# Currently these subjects aren't processing\n",
    "drop = ['sub-058','sub-143']\n",
    "#drop=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring Subject (did it error out?) sub-058\n",
      "Dropping the following subjects ['sub-058', 'sub-143', 'sub-058']\n",
      "Ignoring Subject (did it error out?) sub-058\n",
      "Dropping the following subjects ['sub-058', 'sub-143', 'sub-058']\n"
     ]
    }
   ],
   "source": [
    "# Load DecNef data into dataframes.  For volumetric data we can either load in vals in mm^3, or %icv.\n",
    "# And each load returns the measurement value as well as the normative percentile estimate\n",
    "decnef_vol_df, decnef_vol_norm_df = load_dataset(decnef_dir, decnef_tsv, drop_subjects=['sub-058','sub-143'], vol_data_src='volume')\n",
    "decnef_picv_df, decnef_picv_norm_df = load_dataset(decnef_dir, decnef_tsv, drop_subjects=['sub-058','sub-143'], vol_data_src='volume_percent_icv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "structs_of_interest = [\n",
    "    'BrainSegVolNotVentSurf',\n",
    "    'Left-Amygdala',\n",
    "    'Left-Caudate',\n",
    "    'Left-Cerebellum',\n",
    "    'Left-Hippocampus',\n",
    "    'Left-Lateral-Ventricle',\n",
    "    'Left-Putamen',\n",
    "    'Left-Thalamus',\n",
    "    'Left-White-Matter',\n",
    "    'Right-Amygdala',\n",
    "    'Right-Caudate',\n",
    "    'Right-Cerebellum',\n",
    "    'Right-Hippocampus',\n",
    "    'Right-Lateral-Ventricle',\n",
    "    'Right-Putamen',\n",
    "    'Right-Thalamus',\n",
    "    'Right-White-Matter',\n",
    "    'TotalGrayVol',\n",
    "    'White-Matter',\n",
    "    'lh_cortex_volume',\n",
    "    'lh_frontal_volume',\n",
    "    'lh_occipital_volume',\n",
    "    'lh_parietal_volume',\n",
    "    'lh_temporal_volume',\n",
    "    'rh_cortex_volume',\n",
    "    'rh_frontal_volume',\n",
    "    'rh_occipital_volume',\n",
    "    'rh_parietal_volume',\n",
    "    'rh_temporal_volume',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structs_of_interest = [\n",
    "    'BrainSegVolNotVentSurf',\n",
    "    'TotalGrayVol',\n",
    "    'White-Matter',\n",
    "    'lh_cortex_volume',\n",
    "    'lh_frontal_volume',\n",
    "    'lh_parietal_volume',\n",
    "    'lh_occipital_volume',\n",
    "    'lh_temporal_volume',\n",
    "    'Left-White-Matter',\n",
    "    'Left-Lateral-Ventricle',\n",
    "    'Left-Hippocampus',\n",
    "    'Left-Amygdala',\n",
    "    'Left-Caudate',\n",
    "    'Left-Putamen',\n",
    "    'Left-Thalamus',\n",
    "    'Left-Cerebellum',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column name that holds session info in the demographics.tsv\n",
    "session_col='manufacturer'\n",
    "# The column name that holds subject info in the demographics.tsv\n",
    "subject_col='Subject'\n",
    "\n",
    "session_list= ['Siemens','GE','Philips']\n",
    "subject_list= ['MP001','MP002','MP003','MP004','MP005','MP006','MP007','MP008','MP009']\n",
    "\n",
    "cvs = calc_cvs(decnef_vol_df,subject_list,session_list,subject_col,session_col,structs_of_interest,method='gluer')\n",
    "#cvs_icv = calc_cvs(decnef_picv_df,subject_list,session_list,subject_col,session_col,structs_of_interest,method='gluer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrainSegVolNotVentSurf</th>\n",
       "      <th>TotalGrayVol</th>\n",
       "      <th>White-Matter</th>\n",
       "      <th>lh_cortex_volume</th>\n",
       "      <th>lh_frontal_volume</th>\n",
       "      <th>lh_parietal_volume</th>\n",
       "      <th>lh_occipital_volume</th>\n",
       "      <th>lh_temporal_volume</th>\n",
       "      <th>Left-White-Matter</th>\n",
       "      <th>Left-Lateral-Ventricle</th>\n",
       "      <th>Left-Hippocampus</th>\n",
       "      <th>Left-Amygdala</th>\n",
       "      <th>Left-Caudate</th>\n",
       "      <th>Left-Putamen</th>\n",
       "      <th>Left-Thalamus</th>\n",
       "      <th>Left-Cerebellum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean-vol</th>\n",
       "      <td>1.161740e+06</td>\n",
       "      <td>651760.255319</td>\n",
       "      <td>481238.617021</td>\n",
       "      <td>267538.730496</td>\n",
       "      <td>94912.226950</td>\n",
       "      <td>64837.836879</td>\n",
       "      <td>26999.659574</td>\n",
       "      <td>61884.638298</td>\n",
       "      <td>240648.886525</td>\n",
       "      <td>9599.343262</td>\n",
       "      <td>4250.178014</td>\n",
       "      <td>1770.090071</td>\n",
       "      <td>3661.550355</td>\n",
       "      <td>5737.699291</td>\n",
       "      <td>6742.023404</td>\n",
       "      <td>68519.335461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total-cov</th>\n",
       "      <td>1.728893e+00</td>\n",
       "      <td>3.059304</td>\n",
       "      <td>1.818740</td>\n",
       "      <td>3.338905</td>\n",
       "      <td>3.087655</td>\n",
       "      <td>5.325869</td>\n",
       "      <td>6.264046</td>\n",
       "      <td>3.056007</td>\n",
       "      <td>1.834819</td>\n",
       "      <td>6.428293</td>\n",
       "      <td>4.281713</td>\n",
       "      <td>3.077261</td>\n",
       "      <td>2.158702</td>\n",
       "      <td>3.806735</td>\n",
       "      <td>2.992298</td>\n",
       "      <td>1.811503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session-cov</th>\n",
       "      <td>1.574915e+00</td>\n",
       "      <td>2.533142</td>\n",
       "      <td>1.758274</td>\n",
       "      <td>2.839471</td>\n",
       "      <td>2.537918</td>\n",
       "      <td>4.737042</td>\n",
       "      <td>6.343259</td>\n",
       "      <td>3.034078</td>\n",
       "      <td>1.724281</td>\n",
       "      <td>4.788029</td>\n",
       "      <td>3.034672</td>\n",
       "      <td>3.162755</td>\n",
       "      <td>2.058457</td>\n",
       "      <td>2.428675</td>\n",
       "      <td>2.805122</td>\n",
       "      <td>1.833613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs-diff-cov</th>\n",
       "      <td>1.539779e-01</td>\n",
       "      <td>0.526162</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.499433</td>\n",
       "      <td>0.549737</td>\n",
       "      <td>0.588826</td>\n",
       "      <td>0.079213</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>1.640264</td>\n",
       "      <td>1.247041</td>\n",
       "      <td>0.085494</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>1.378060</td>\n",
       "      <td>0.187176</td>\n",
       "      <td>0.022110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-vals</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.863000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BrainSegVolNotVentSurf   TotalGrayVol   White-Matter  \\\n",
       "mean-vol                1.161740e+06  651760.255319  481238.617021   \n",
       "total-cov               1.728893e+00       3.059304       1.818740   \n",
       "session-cov             1.574915e+00       2.533142       1.758274   \n",
       "abs-diff-cov            1.539779e-01       0.526162       0.060466   \n",
       "p-vals                  0.000000e+00       0.000000       0.599000   \n",
       "\n",
       "              lh_cortex_volume  lh_frontal_volume  lh_parietal_volume  \\\n",
       "mean-vol         267538.730496       94912.226950        64837.836879   \n",
       "total-cov             3.338905           3.087655            5.325869   \n",
       "session-cov           2.839471           2.537918            4.737042   \n",
       "abs-diff-cov          0.499433           0.549737            0.588826   \n",
       "p-vals                0.000000           0.000000            0.000000   \n",
       "\n",
       "              lh_occipital_volume  lh_temporal_volume  Left-White-Matter  \\\n",
       "mean-vol             26999.659574        61884.638298      240648.886525   \n",
       "total-cov                6.264046            3.056007           1.834819   \n",
       "session-cov              6.343259            3.034078           1.724281   \n",
       "abs-diff-cov             0.079213            0.021929           0.110538   \n",
       "p-vals                   0.843000            0.927000           0.185000   \n",
       "\n",
       "              Left-Lateral-Ventricle  Left-Hippocampus  Left-Amygdala  \\\n",
       "mean-vol                 9599.343262       4250.178014    1770.090071   \n",
       "total-cov                   6.428293          4.281713       3.077261   \n",
       "session-cov                 4.788029          3.034672       3.162755   \n",
       "abs-diff-cov                1.640264          1.247041       0.085494   \n",
       "p-vals                      0.000000          0.000000       0.608000   \n",
       "\n",
       "              Left-Caudate  Left-Putamen  Left-Thalamus  Left-Cerebellum  \n",
       "mean-vol       3661.550355   5737.699291    6742.023404     68519.335461  \n",
       "total-cov         2.158702      3.806735       2.992298         1.811503  \n",
       "session-cov       2.058457      2.428675       2.805122         1.833613  \n",
       "abs-diff-cov      0.100245      1.378060       0.187176         0.022110  \n",
       "p-vals            0.350000      0.000000       0.421000         0.863000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "monte_carlo_perm_test(decnef_vol_df, subject_list, session_list, subject_col, session_col, structs_of_interest, n_itrs=n, method='gluer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
